# Import Libraries
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from xgboost import XGBClassifier

# Load Data
train_data = pd.read_csv("/kaggle/input/titanic/train.csv")
test_data = pd.read_csv("/kaggle/input/titanic/test.csv")

# Feature Engineering
# Fill missing values for Age and Fare with median
imputer = SimpleImputer(strategy="median")
train_data['Age'] = imputer.fit_transform(train_data[['Age']])
test_data['Age'] = imputer.transform(test_data[['Age']])
train_data['Fare'] = imputer.fit_transform(train_data[['Fare']])
test_data['Fare'] = imputer.transform(test_data[['Fare']])

# Fill missing values for Embarked with mode
train_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace=True)
test_data['Embarked'].fillna(test_data['Embarked'].mode()[0], inplace=True)

# Create new features
train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1
test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1
train_data['IsAlone'] = (train_data['FamilySize'] == 1).astype(int)
test_data['IsAlone'] = (test_data['FamilySize'] == 1).astype(int)

# Extract titles from names
train_data['Title'] = train_data['Name'].apply(lambda name: name.split(',')[1].split('.')[0].strip())
test_data['Title'] = test_data['Name'].apply(lambda name: name.split(',')[1].split('.')[0].strip())

# Bin Age and Fare
train_data['AgeBin'] = pd.qcut(train_data['Age'], 4, labels=False)
test_data['AgeBin'] = pd.qcut(test_data['Age'], 4, labels=False)
train_data['FareBin'] = pd.qcut(train_data['Fare'], 4, labels=False)
test_data['FareBin'] = pd.qcut(test_data['Fare'], 4, labels=False)

# Prepare Features and Target
features = ["Pclass", "Sex", "AgeBin", "SibSp", "Parch", "FareBin", "Embarked", "FamilySize", "IsAlone", "Title"]
X = pd.get_dummies(train_data[features])
X_test = pd.get_dummies(test_data[features])
y = train_data["Survived"]

# Standardize Numerical Features
scaler = StandardScaler()
X[['FamilySize']] = scaler.fit_transform(X[['FamilySize']])
X_test[['FamilySize']] = scaler.transform(X_test[['FamilySize']])

# Model Definitions and Hyperparameter Tuning
# Logistic Regression
logistic_model = LogisticRegression(max_iter=1000, random_state=1)
logistic_cv_score = cross_val_score(logistic_model, X, y, cv=5, scoring='accuracy').mean()

# Gradient Boosting with GridSearchCV for Hyperparameter Tuning
gb_param_grid = {
    'n_estimators': [150, 200, 250],
    'learning_rate': [0.05, 0.1, 0.15],
    'max_depth': [3, 4, 5]
}
grid_search_gb = GridSearchCV(GradientBoostingClassifier(random_state=1), gb_param_grid, cv=5, scoring='accuracy')
grid_search_gb.fit(X, y)
best_gb_model = grid_search_gb.best_estimator_

# XGBoost with parameter tuning
xgb_param_grid = {
    'n_estimators': [100, 150, 200],
    'learning_rate': [0.05, 0.1],
    'max_depth': [3, 4, 5]
}
grid_search_xgb = GridSearchCV(XGBClassifier(random_state=1, use_label_encoder=False, eval_metric='logloss'), xgb_param_grid, cv=5, scoring='accuracy')
grid_search_xgb.fit(X, y)
best_xgb_model = grid_search_xgb.best_estimator_

# Ensemble Model with Voting Classifier
ensemble_model = VotingClassifier(estimators=[
    ('logistic', logistic_model),
    ('gradient_boosting', best_gb_model),
    ('xgboost', best_xgb_model)
], voting='soft')
ensemble_cv_score = cross_val_score(ensemble_model, X, y, cv=5, scoring='accuracy').mean()

# Display results
print(f"Logistic Regression CV Accuracy: {logistic_cv_score:.4f}")
print(f"Optimized Gradient Boosting CV Accuracy: {grid_search_gb.best_score_:.4f}")
print(f"Optimized XGBoost CV Accuracy: {grid_search_xgb.best_score_:.4f}")
print(f"Ensemble Model CV Accuracy: {ensemble_cv_score:.4f}")

# Train Final Ensemble Model and Make Predictions
ensemble_model.fit(X, y)
ensemble_predictions = ensemble_model.predict(X_test)

# Save Predictions to CSV
ensemble_output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': ensemble_predictions})
ensemble_output.to_csv('ensemble_submission.csv', index=False)
print("Ensemble submission saved as ensemble_submission.csv")
