# Cell 1: Import Libraries
import pandas as pd
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import f1_score

# Cell 2: Load Data
# Replace '/path/to/train.csv' and '/path/to/test.csv' with the actual file paths
train_df = pd.read_csv('/path/to/train.csv')
test_df = pd.read_csv('/path/to/test.csv')

# Cell 3: Define Preprocessing Function
def preprocess_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r"http\S+|www\S+|https\S+|@\S+|#\S+", '', text, flags=re.MULTILINE)  # Remove URLs and mentions
    text = re.sub(r'\W+', ' ', text)  # Remove special characters
    return text

# Apply preprocessing to train and test datasets
train_df['cleaned_text'] = train_df['text'].apply(preprocess_text)
test_df['cleaned_text'] = test_df['text'].apply(preprocess_text)

# Cell 4: TF-IDF Vectorization
tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 3), max_df=0.9, min_df=3)
X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['cleaned_text'])
X_test_tfidf = tfidf_vectorizer.transform(test_df['cleaned_text'])

# Separate features and target variable in the training set
X = X_train_tfidf
y = train_df['target']

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Cell 5: Logistic Regression Model Tuning
log_reg = LogisticRegression(max_iter=1000)
log_param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}
log_grid_search = GridSearchCV(log_reg, log_param_grid, scoring='f1', cv=5)
log_grid_search.fit(X_train, y_train)
best_log_reg = log_grid_search.best_estimator_

# Cell 6: Random Forest Model Tuning
rf = RandomForestClassifier(random_state=42)
rf_param_grid = {'n_estimators': [100, 300], 'max_depth': [10, 50]}
rf_grid_search = GridSearchCV(rf, rf_param_grid, scoring='f1', cv=5)
rf_grid_search.fit(X_train, y_train)
best_rf = rf_grid_search.best_estimator_

# Cell 7: Ensemble Model - Voting Classifier
voting_clf = VotingClassifier(estimators=[('lr', best_log_reg), ('rf', best_rf)], voting='soft')
voting_clf.fit(X_train, y_train)

# Cell 8: Validate the Ensemble Model
y_val_pred = voting_clf.predict(X_val)
ensemble_f1 = f1_score(y_val, y_val_pred)
print("Validation F1 Score for Ensemble Model:", ensemble_f1)

# Cell 9: Generate Predictions on the Test Set
test_predictions = voting_clf.predict(X_test_tfidf)

# Cell 10: Prepare and Save Submission File
submission_df = pd.DataFrame({
    'id': test_df['id'],
    'target': test_predictions
})

# Replace '/path/to/optimized_ensemble_submission.csv' with the actual save path
submission_file_path = '/path/to/optimized_ensemble_submission.csv'
submission_df.to_csv(submission_file_path, index=False)
print(f"Submission file saved as '{submission_file_path}'")
